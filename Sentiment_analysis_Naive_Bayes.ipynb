{"cells":[{"cell_type":"code","source":["!pip install nltk"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e03aab0a-9f9a-4967-88fe-697659159448"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import QuantileDiscretizer\nfrom pyspark.sql.types import *\nfrom pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier,NaiveBayes,RandomForestClassifier\nfrom pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\nfrom pyspark.sql.functions import udf, col, lower, trim, regexp_replace\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover\nfrom nltk.stem.snowball import SnowballStemmer # BE SURE NLTK IS INSTALLED ON THE CLUSTER USING THE \"LIBRARIES\" TAB IN THE MENU\n\n\n# Importing the feature transformation classes for doing TF-IDF \nfrom pyspark.ml.feature import HashingTF, CountVectorizer, IDF, NGram\nfrom pyspark.ml import Pipeline\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\nimport matplotlib.pyplot as plt\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21f205bd-a4ea-4ac7-b800-405eec07108e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#obje oluşturmak için sparksession.\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Spark ML example on twitter data \") \\\n    .getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62a130db-78d6-40c9-b19b-71971e3c1437"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["RANDOM_SEED = 42 # used below to run the actual K-means clustering\nVOCAB_SIZE = 1000 # number of words to be retained as vocabulary\nMIN_DOC_FREQ = 10 # minimum number of documents a word has to appear in to be included in the vocabulary\nN_GRAMS = 2 # number of n-grams (if needed)\nN_FEATURES = 200 # default embedding vector size (if HashingTF or, later, Word2Vec are used)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"573b76c5-e2f8-45ef-8830-8c1461893091"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# CSV dosyasını okuma.\n#dataset = \"/FileStore/tables/testdata_manual_2009_06_14-4.csv\"\ndataset = \"dbfs:/datasets/train.csv\"\ndf = spark.read.csv(dataset,header = 'False',inferSchema='True')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a45811b-3c86-4eb3-b3d8-dd90128b0ce5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = df.select(col(\"_c0\").alias(\"polarite\"), col(\"_c1\").alias(\"id\"), col(\"_c2\").alias(\"date\"), col(\"_c3\").alias(\"query\"), col(\"_c4\").alias(\"user_name\"), col(\"_c5\").alias(\"tweet\"))\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2a65e83-ae3e-40c9-bd6d-04793f312dec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+-------------+--------------------+--------+---------------+--------------------+\n|polarite|           id|                date|   query|      user_name|               tweet|\n+--------+-------------+--------------------+--------+---------------+--------------------+\n|     0.0|1.467810369E9|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n|     0.0|1.467810672E9|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n|     0.0|1.467810917E9|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n|     0.0|1.467811184E9|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n|     0.0|1.467811193E9|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n|     0.0|1.467811372E9|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n|     0.0|1.467811592E9|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|          Need a hug|\n|     0.0|1.467811594E9|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n|     0.0|1.467811795E9|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n|     0.0|1.467812025E9|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n|     0.0|1.467812416E9|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n|     0.0|1.467812579E9|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n|     0.0|1.467812723E9|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n|     0.0|1.467812771E9|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n|     0.0|1.467812784E9|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n|     0.0|1.467812799E9|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n|     0.0|1.467812964E9|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n|     0.0|1.467813137E9|Mon Apr 06 22:20:...|NO_QUERY|       armotley| about to file taxes|\n|     0.0|1.467813579E9|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n|     0.0|1.467813782E9|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n+--------+-------------+--------------------+--------+---------------+--------------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+-------------+--------------------+--------+---------------+--------------------+\n|polarite|           id|                date|   query|      user_name|               tweet|\n+--------+-------------+--------------------+--------+---------------+--------------------+\n|     0.0|1.467810369E9|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n|     0.0|1.467810672E9|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n|     0.0|1.467810917E9|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n|     0.0|1.467811184E9|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n|     0.0|1.467811193E9|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n|     0.0|1.467811372E9|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n|     0.0|1.467811592E9|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|          Need a hug|\n|     0.0|1.467811594E9|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n|     0.0|1.467811795E9|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n|     0.0|1.467812025E9|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n|     0.0|1.467812416E9|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n|     0.0|1.467812579E9|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n|     0.0|1.467812723E9|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n|     0.0|1.467812771E9|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n|     0.0|1.467812784E9|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n|     0.0|1.467812799E9|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n|     0.0|1.467812964E9|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n|     0.0|1.467813137E9|Mon Apr 06 22:20:...|NO_QUERY|       armotley| about to file taxes|\n|     0.0|1.467813579E9|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n|     0.0|1.467813782E9|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n+--------+-------------+--------------------+--------+---------------+--------------------+\nonly showing top 20 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import when\ndf = df.withColumn(\"polarite\", when(df.polarite == \"0.0\",\"0\") \\\n      .when(df.polarite == \"4.0\",\"1\") \\\n      .otherwise(df.polarite))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3de4453-e4ed-4d46-8200-79d03c1aea6f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.groupBy(\"polarite\").count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6fbf5db-cf22-44d7-8b83-18d8fb49454e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+------+\n|polarite| count|\n+--------+------+\n|       0|784103|\n|       1|778833|\n+--------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+------+\n|polarite| count|\n+--------+------+\n|       0|784103|\n|       1|778833|\n+--------+------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Import the required packages\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import NaiveBayes\nstages = []\n# 1. clean data and tokenize sentences using RegexTokenizer\nregexTokenizer = RegexTokenizer(inputCol=\"tweet\", outputCol=\"tokens\", pattern=\"\\\\W+\")\nstages += [regexTokenizer]\n\n# 2. CountVectorize the data\ncv = CountVectorizer(inputCol=\"tokens\", outputCol=\"token_features\", minDF=2.0)#, vocabSize=3, minDF=2.0\nstages += [cv]\n\n# 3. Convert the labels to numerical values using binariser\n#indexer = StringIndexer(inputCol=\"polarite\", outputCol=\"label\")\n#stages += [indexer]\n\n# 4. Vectorise features using vectorassembler\nvecAssembler = VectorAssembler(inputCols=['token_features'], outputCol=\"features\")\nstages += [vecAssembler]\n\n[print('\\n', stage) for stage in stages]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23c1c725-c27e-4aae-9d35-df35d4ee9066"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n RegexTokenizer_7cf3c5ff2f2f\n\n CountVectorizer_d1dbaecc9eec\n\n VectorAssembler_bc07b02ed115\nOut[11]: [None, None, None]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\n RegexTokenizer_7cf3c5ff2f2f\n\n CountVectorizer_d1dbaecc9eec\n\n VectorAssembler_bc07b02ed115\nOut[11]: [None, None, None]"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml import Pipeline\npipeline = Pipeline(stages=stages)\ndata = pipeline.fit(df).transform(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"006aeb4b-cc6a-46f0-ae32-ee7535f379c7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data.printSchema()\nfrom pyspark.sql.types import IntegerType,DoubleType\ndata = data.withColumn(\"polarite\", data[\"polarite\"].cast(DoubleType()))\ndata.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e340f1c-b44e-4a8b-8d47-1ba1199fab05"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- polarite: string (nullable = true)\n |-- id: double (nullable = true)\n |-- date: string (nullable = true)\n |-- query: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- tweet: string (nullable = true)\n |-- tokens: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- token_features: vector (nullable = true)\n |-- features: vector (nullable = true)\n\nroot\n |-- polarite: double (nullable = true)\n |-- id: double (nullable = true)\n |-- date: string (nullable = true)\n |-- query: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- tweet: string (nullable = true)\n |-- tokens: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- token_features: vector (nullable = true)\n |-- features: vector (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- polarite: string (nullable = true)\n |-- id: double (nullable = true)\n |-- date: string (nullable = true)\n |-- query: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- tweet: string (nullable = true)\n |-- tokens: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- token_features: vector (nullable = true)\n |-- features: vector (nullable = true)\n\nroot\n |-- polarite: double (nullable = true)\n |-- id: double (nullable = true)\n |-- date: string (nullable = true)\n |-- query: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- tweet: string (nullable = true)\n |-- tokens: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- token_features: vector (nullable = true)\n |-- features: vector (nullable = true)\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["train, test = data.randomSplit([0.7, 0.3], seed = 2018)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14802f1e-7556-41c2-9bf7-7519fb4461cf"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\n# Initialise the model\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\",labelCol='polarite')\n# Fit the model\nmodel = nb.fit(train)\n# Make predictions on test data\npredictions = model.transform(test)\npredictions.select(\"polarite\", \"prediction\", \"probability\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Naive Bayes","showTitle":true,"inputWidgets":{},"nuid":"35f9f3a9-84ef-4d66-aa3a-695b9cbe6ba9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+----------+--------------------+\n|polarite|prediction|         probability|\n+--------+----------+--------------------+\n|     0.0|       1.0|[0.29702795399708...|\n|     0.0|       0.0|[0.95543756293950...|\n|     0.0|       0.0|[0.51273007935153...|\n|     0.0|       0.0|[0.99238278637524...|\n|     0.0|       0.0|[0.93829387451755...|\n|     0.0|       1.0|[0.13846088455383...|\n|     0.0|       0.0|[0.93499527813530...|\n|     0.0|       0.0|[0.88535992522793...|\n|     0.0|       0.0|[0.97514361411782...|\n|     0.0|       0.0|[0.78557214430375...|\n|     0.0|       0.0|[0.99968588054449...|\n|     0.0|       0.0|[0.98979135891167...|\n|     0.0|       0.0|[0.99999998950176...|\n|     0.0|       0.0|[0.99355554072012...|\n|     0.0|       0.0|[0.96176367607767...|\n|     0.0|       0.0|[0.88173510171205...|\n|     0.0|       0.0|[0.93184230782056...|\n|     0.0|       0.0|[0.63369391428442...|\n|     0.0|       1.0|[0.34513447279035...|\n|     0.0|       1.0|[0.35161001377571...|\n+--------+----------+--------------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+----------+--------------------+\n|polarite|prediction|         probability|\n+--------+----------+--------------------+\n|     0.0|       1.0|[0.29702795399708...|\n|     0.0|       0.0|[0.95543756293950...|\n|     0.0|       0.0|[0.51273007935153...|\n|     0.0|       0.0|[0.99238278637524...|\n|     0.0|       0.0|[0.93829387451755...|\n|     0.0|       1.0|[0.13846088455383...|\n|     0.0|       0.0|[0.93499527813530...|\n|     0.0|       0.0|[0.88535992522793...|\n|     0.0|       0.0|[0.97514361411782...|\n|     0.0|       0.0|[0.78557214430375...|\n|     0.0|       0.0|[0.99968588054449...|\n|     0.0|       0.0|[0.98979135891167...|\n|     0.0|       0.0|[0.99999998950176...|\n|     0.0|       0.0|[0.99355554072012...|\n|     0.0|       0.0|[0.96176367607767...|\n|     0.0|       0.0|[0.88173510171205...|\n|     0.0|       0.0|[0.93184230782056...|\n|     0.0|       0.0|[0.63369391428442...|\n|     0.0|       1.0|[0.34513447279035...|\n|     0.0|       1.0|[0.35161001377571...|\n+--------+----------+--------------------+\nonly showing top 20 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(labelCol=\"polarite\", predictionCol=\"prediction\")\naccuracy = evaluator.evaluate(predictions)\nprint (\"Model Accuracy: \", accuracy)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa528b3a-8f4a-4c79-b2df-372233703715"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Model Accuracy:  0.7822402467375877\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Model Accuracy:  0.7822402467375877\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"polarite\", predictionCol=\"prediction\")\npredictionFinal_rf_g = predictions.select(\n    \"tweet\", \"prediction\", \"polarite\")\npredictionFinal_rf_g.show(n=4, truncate = False)\ncorrectPrediction_rf_g = predictionFinal_rf_g.filter(\n    predictionFinal_rf_g['prediction'] == predictionFinal_rf_g['polarite']).count()\ntotalData_rf_g = predictionFinal_rf_g.count()\nprint(\"correct prediction:\", correctPrediction_rf_g, \", total data:\", totalData_rf_g, \n      \", accuracy:\", correctPrediction_rf_g/totalData_rf_g)\n\n\n\npreds_and_labels_rf_g = predictions.select(['prediction','polarite'])\n\nmetrics_rf_g = MulticlassMetrics(preds_and_labels_rf_g.rdd.map(tuple))\n\nprecision_0_rf_g = metrics_rf_g.precision(0.0)\nrecall_0_rf_g = metrics_rf_g.recall(0.0)\nprecision_4_rf_g = metrics_rf_g.precision(1.0)\nrecall_4_rf_g = metrics_rf_g.recall(1.0)\nf1Score_rf_g = metrics_rf_g.fMeasure(0.0,1.0)\nprint(\"Summary Stats\")\nprint(\"Precision 0 = %s\" % precision_0_rf_g)\nprint(\"Recall 0 = %s\" % recall_0_rf_g)\nprint(\"Precision 4 = %s\" % precision_4_rf_g)\nprint(\"Recall 4 = %s\" % recall_4_rf_g)\nprint(\"F1 Score = %s\" % f1Score_rf_g)\nprint(metrics_rf_g.confusionMatrix().toArray())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08de34a6-75a0-4e6d-a691-a42b9c8032b7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|tweet                                                                                                              |prediction|polarite|\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|1.0       |0.0     |\n|@Tatiana_K nope they didn't have it                                                                                |0.0       |0.0     |\n|I just re-pierced my ears                                                                                          |0.0       |0.0     |\n|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                     |0.0       |0.0     |\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\nonly showing top 4 rows\n\ncorrect prediction: 367361 , total data: 469547 , accuracy: 0.7823732235537656\nSummary Stats\nPrecision 0 = 0.7702432312868571\nRecall 0 = 0.8063537519597888\nPrecision 4 = 0.795766190467655\nRecall 4 = 0.7582731969768137\nF1 Score = 0.7878849522987122\n[[189781.  45576.]\n [ 56610. 177580.]]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|tweet                                                                                                              |prediction|polarite|\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|1.0       |0.0     |\n|@Tatiana_K nope they didn't have it                                                                                |0.0       |0.0     |\n|I just re-pierced my ears                                                                                          |0.0       |0.0     |\n|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                     |0.0       |0.0     |\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\nonly showing top 4 rows\n\ncorrect prediction: 367361 , total data: 469547 , accuracy: 0.7823732235537656\nSummary Stats\nPrecision 0 = 0.7702432312868571\nRecall 0 = 0.8063537519597888\nPrecision 4 = 0.795766190467655\nRecall 4 = 0.7582731969768137\nF1 Score = 0.7878849522987122\n[[189781.  45576.]\n [ 56610. 177580.]]\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["nbparamGrid = (ParamGridBuilder()\n               .addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n               .build())\n\n\nml_class = MulticlassClassificationEvaluator(labelCol=\"polarite\", predictionCol=\"prediction\")\ncrossval = CrossValidator(estimator=nb,\n                          estimatorParamMaps=nbparamGrid,\n                          evaluator=ml_class,\n                          numFolds=2)\n\ncvModel = crossval.fit(train)\n\npredictions = cvModel.transform(test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cec24ec3-2961-479c-afc6-31a8961e95e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/spark/python/pyspark/ml/util.py:839: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/spark/python/pyspark/ml/util.py:839: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"polarite\", predictionCol=\"prediction\")\npredictionFinal_rf_g = predictions.select(\n    \"tweet\", \"prediction\", \"polarite\")\npredictionFinal_rf_g.show(n=4, truncate = False)\ncorrectPrediction_rf_g = predictionFinal_rf_g.filter(\n    predictionFinal_rf_g['prediction'] == predictionFinal_rf_g['polarite']).count()\ntotalData_rf_g = predictionFinal_rf_g.count()\nprint(\"correct prediction:\", correctPrediction_rf_g, \", total data:\", totalData_rf_g, \n      \", accuracy:\", correctPrediction_rf_g/totalData_rf_g)\n\n\n\npreds_and_labels_rf_g = predictions.select(['prediction','polarite'])\n\nmetrics_rf_g = MulticlassMetrics(preds_and_labels_rf_g.rdd.map(tuple))\n\nprecision_0_rf_g = metrics_rf_g.precision(0.0)\nrecall_0_rf_g = metrics_rf_g.recall(0.0)\nprecision_4_rf_g = metrics_rf_g.precision(1.0)\nrecall_4_rf_g = metrics_rf_g.recall(1.0)\nf1Score_rf_g = metrics_rf_g.fMeasure(0.0,1.0)\nprint(\"Summary Stats\")\nprint(\"Precision 0 = %s\" % precision_0_rf_g)\nprint(\"Recall 0 = %s\" % recall_0_rf_g)\nprint(\"Precision 4 = %s\" % precision_4_rf_g)\nprint(\"Recall 4 = %s\" % recall_4_rf_g)\nprint(\"F1 Score = %s\" % f1Score_rf_g)\nprint(metrics_rf_g.confusionMatrix().toArray())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"537a5e7c-fda1-4486-8d8c-38887ec8110f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|tweet                                                                                                              |prediction|polarite|\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|1.0       |0.0     |\n|@Tatiana_K nope they didn't have it                                                                                |0.0       |0.0     |\n|I just re-pierced my ears                                                                                          |0.0       |0.0     |\n|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                     |0.0       |0.0     |\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\nonly showing top 4 rows\n\ncorrect prediction: 367361 , total data: 469547 , accuracy: 0.7823732235537656\nSummary Stats\nPrecision 0 = 0.7702432312868571\nRecall 0 = 0.8063537519597888\nPrecision 4 = 0.795766190467655\nRecall 4 = 0.7582731969768137\nF1 Score = 0.7878849522987122\n[[189781.  45576.]\n [ 56610. 177580.]]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|tweet                                                                                                              |prediction|polarite|\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\n|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|1.0       |0.0     |\n|@Tatiana_K nope they didn't have it                                                                                |0.0       |0.0     |\n|I just re-pierced my ears                                                                                          |0.0       |0.0     |\n|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                     |0.0       |0.0     |\n+-------------------------------------------------------------------------------------------------------------------+----------+--------+\nonly showing top 4 rows\n\ncorrect prediction: 367361 , total data: 469547 , accuracy: 0.7823732235537656\nSummary Stats\nPrecision 0 = 0.7702432312868571\nRecall 0 = 0.8063537519597888\nPrecision 4 = 0.795766190467655\nRecall 4 = 0.7582731969768137\nF1 Score = 0.7878849522987122\n[[189781.  45576.]\n [ 56610. 177580.]]\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef81ab46-43ce-4185-968d-e1a964f1fe92"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Sentiment_analysis_Naive_Bayes","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1695495040693160}},"nbformat":4,"nbformat_minor":0}
